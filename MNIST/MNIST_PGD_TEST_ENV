import os
import numpy as np
import matplotlib.pyplot as plt
import torchvision.models as models
import torch
import torch.nn as nn
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import torch.nn.functional as F
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
from PIL import Image


# Check for GPU availability
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")


net = models.resnet18(weights=None, num_classes=10)
net.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) # Modify the first convolutional layer to accept 1 input channel
net.to(device) #Move model to the GPU

try:
    net.load_state_dict(torch.load('/content/best_resnet18_MINST_97-59.pth', map_location=torch.device(device)))
    net.eval()
except FileNotFoundError:
    print("Error: Model file not found. Ensure '/content/best_resnet18_MINST_97-59.pth' exists.")
    exit(1)

def save_image_with_classification(image_data, classification, filepath):
    image = np.transpose(image_data.squeeze(0).detach().cpu().numpy(), (1, 2, 0)) # Move image back to cpu before converting to numpy
    image = np.clip(image, 0, 1)
    plt.imshow(image)
    plt.title(classification)
    plt.axis('off')
    plt.savefig(filepath)
    plt.close()

def save_confusion_matrix(cm, class_names, filepath, cmap='Blues'):
    def get_unique_filepath(filepath):
        base, ext = os.path.splitext(filepath)
        counter = 1
        unique_filepath = filepath
        while os.path.exists(unique_filepath):
            unique_filepath = f"{base}_{counter}{ext}"
            counter += 1
        return unique_filepath

    unique_filepath = get_unique_filepath(filepath)
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap=cmap, xticklabels=class_names, yticklabels=class_names)
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.savefig(unique_filepath)
    plt.close()

def save_perturbation_heatmap(original, adversarial, filepath):
    #calculate absolute diff
    perturbation = (adversarial - original).detach().cpu().squeeze(0).numpy()
    perturbation = np.abs(perturbation)

    plt.figure(figsize=(4, 4))
    sns.heatmap(perturbation[0], cmap='viridis', cbar=True, square=True)
    plt.title('Adversarial Perturbation Heatmap')
    plt.axis('off')
    plt.tight_layout()
    plt.savefig(filepath)
    plt.close()

def save_combined_visualization(original, adversarial, pred_label, true_label, index, output_dir):
    orig_np = original.detach().cpu().squeeze(0).numpy()
    adv_np = adversarial.detach().cpu().squeeze(0).numpy()
    perturbation = np.abs(adv_np - orig_np)

    # Reshape perturbation to 2D if it's 3D
    if perturbation.ndim == 3 and perturbation.shape[0] == 1:  # Check if it's (1, H, W)
        perturbation = perturbation.squeeze(0)  # Remove the channel dimension
    #diff norms
    L2_norm = np.linalg.norm(perturbation, ord=2)
    L1_norm = np.linalg.norm(perturbation, ord=1)
    Linf_norm = np.max(np.abs(perturbation)) # Fixed: Added np.abs for Linf_norm

    #If atack is successful
    success = pred_label != true_label
    edge_color = 'green' if not success else 'red'
    status = "Success" if success else "Fail"

    fig, axs = plt.subplots(1, 3, figsize=(10 ,4))

    axs[0].imshow(orig_np.squeeze(), cmap='gray')
    axs[0].set_title(f'Original\nLabel: {true_label}')
    axs[0].axis('off')

    axs[1].imshow(adv_np.squeeze(), cmap='gray')
    axs[1].set_title(f'Adversarial\nLabel: {pred_label}') # Fixed: Changed predpred_label to pred_label
    axs[1].axis('off') # Fixed: Changed axs[0] to axs[1]

    sns.heatmap(perturbation, ax=axs[2], cmap='viridis', cbar=True, square=True)
    axs[2].set_title('Perturbation Heatmap')
    axs[2].axis('off')

    plt.suptitle(
        f'{status} | L2: {L2_norm:.4f} | L1: {L1_norm:.4f} | Linf: {Linf_norm:.4f}',
        fontsize=12,
        color=edge_color
    )

    for ax in axs:
      for spine in ax.spines.values():
        spine.set_edgecolor(edge_color)
        spine.set_linewidth(2)

    plt.tight_layout(rect=[0, 0.03, 1, 0.95]) #space for suptitle
    filename= os.path.join(output_dir, f'combined_{index}_true_{true_label}_pred_{pred_label}.png')
    plt.savefig(filename)
    plt.close()

def save_as_pdf(image_folder, output_file='combined_visualizations.pdf'):
    images = sorted([os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.endswith('.png')])
    pil_images = [Image.open(img).convert('RGB') for img in images]
    if pil_images:
        pil_images[0].save(output_file, save_all=True, append_images=pil_images[1:])
        print(f"Images saved as {output_file}")
    else:
        print("No images found in the specified folder.")


def pgd_attack(model, data, true_labels, epsilon, step_size, num_steps):
    perturbed_data = data.clone().detach().to(device)  # Move to device
    perturbed_data.requires_grad = True

    for _ in range(num_steps):
        output = model(perturbed_data)
        #loss = F.cross_entropy(output, output.argmax(dim=1))  # Maximize loss for the predicted class
        loss = F.cross_entropy(output, true_labels)

        model.zero_grad()
        loss.backward()

        # Dynamic step size adjustment
        # Either making he step size too small or couse it to fluctuate so i will continue with static value
        # step_size = step_size * (1 + 0.1 * torch.norm(perturbed_data.grad).item())
        # step_size = min(step_size, epsilon / 2)  # Cap step size

        # Gradient ascent step
        perturbed_data = perturbed_data + step_size * perturbed_data.grad.sign()

        # Project back to epsilon-ball
        perturbed_data = torch.min(torch.max(perturbed_data, data - epsilon), data + epsilon)
        perturbed_data = torch.clamp(perturbed_data, 0, 1)

        # Reinitialize gradient
        perturbed_data = perturbed_data.detach()  # Detach to prevent accumulation
        perturbed_data.requires_grad = True

    return perturbed_data

#-------------------------------------------------------------------------------

class_names = datasets.MNIST(root='./data', train=True, download=True).classes

# Data transformation and loading
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.1307,), (0.3081,)) #(0.1307,), (0.3081,)
])
test_data = datasets.MNIST(root='./data', train=False, download=True, transform=transform)
test_loader = DataLoader(test_data, batch_size=1, shuffle=True)


epsilon = 0.01
num_images = 300
output_dir = './output_images'
os.makedirs(output_dir, exist_ok=True)
heatmap_dir = './perturbation_heatmaps'
os.makedirs(heatmap_dir, exist_ok=True)
combined_output_dir = './combined_visualizations'
os.makedirs(combined_output_dir, exist_ok=True)

# PGD parameters
step_size = epsilon / 2 #or try it by dividing to 4 as 0.0025
num_steps = 20

true_labels = []
original_preds = []
adversarial_preds = []

all_labels = []
all_original_preds = []
all_adversarial_preds = []
correct_original = 0
correct_adversarial = 0
num_perturbed_images = 0

#3 tests
for i in range (1):
    for i, (data, target) in enumerate(test_loader):
        if i >= num_images:
            break

        data, target = data.to(device), target.to(device) #Move data and target to the GPU
        all_labels.append(target.item())

        # Original prediction
        with torch.no_grad():
            output = net(data)
        original_pred = output.argmax(dim=1).item()
        all_original_preds.append(original_pred)
        correct_original += (original_pred == target.item())

        original_filepath = os.path.join(output_dir, f'original_{i}_label_{target.item()}.png')
        save_image_with_classification(data, class_names[target.item()], original_filepath)


        # Generate adversarial example
        adversarial_data = pgd_attack(net, data.clone(), target, epsilon=epsilon, step_size=step_size, num_steps=num_steps)

        # heatmap
        heatmap_path = os.path.join(heatmap_dir, f'heatmap_{i}_label_{target.item()}.png')
        save_perturbation_heatmap(data, adversarial_data, heatmap_path)

        # # Calculate average perturbation magnitude
        # diff = (adversarial_data - data).abs().mean().item()
        # print(f"Average perturbation magnitude for image {i}: {diff:.6f}")

        #increment the number of perturbed images
        num_perturbed_images += 1

        # Adversarial prediction
        with torch.no_grad():
            output = net(adversarial_data)
        adversarial_pred = output.argmax(dim=1).item()
        all_adversarial_preds.append(adversarial_pred)
        correct_adversarial += (adversarial_pred == target.item())

        # Save adversarial image
        adversarial_filepath = os.path.join(output_dir, f'adversarial_{i}_label_{target.item()}_target_{target.item()}.png')#Fixed: Added target.item()
        save_image_with_classification(adversarial_data, class_names[adversarial_pred], adversarial_filepath)

        # save combined
        save_combined_visualization(data, adversarial_data, adversarial_pred, target.item(), i, combined_output_dir)

    accuracy_original_before_masking = (correct_original / num_images) * 100
    accuracy_adversarial_before_masking = (correct_adversarial / num_perturbed_images) * 100

    print(f"\nAccuracy on original images: {accuracy_original_before_masking:.2f}%")
    print(f"Accuracy on adversarial images: {accuracy_adversarial_before_masking:.2f}%")

    # Confusion matrices
    cm_original = confusion_matrix(all_labels, all_original_preds)
    cm_adversarial = confusion_matrix(all_labels, all_adversarial_preds)

    #Combined pdf
    save_as_pdf(combined_output_dir, output_file='combined_visualizations.pdf')

    # Save confusion matrices as images with unique names
    save_confusion_matrix(cm_original, class_names, f'cm-with-original-{num_images}.png', cmap='Blues')
    save_confusion_matrix(cm_adversarial, class_names, f'cm-with-adversarial-{num_images}.png', cmap='Reds')

    all_labels = []
    all_original_preds = []
    all_adversarial_preds = []
    correct_original = 0
    correct_adversarial = 0
    num_perturbed_images = 0
