import os
import numpy as np
import matplotlib.pyplot as plt
import torchvision.models as models
import torch
import torch.nn as nn
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

net = models.resnet18(weights=None, num_classes=10)
net.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) # Modify the first convolutional layer to accept 1 input channel

try:
    net.load_state_dict(torch.load('/content/best_resnet18_MINST_97-59.pth', map_location=torch.device('cpu')))
    net.eval()
except FileNotFoundError:
    print("Error: Model file not found. Ensure '/content/best_resnet18_MINST_97-59.pth' exists.")
    exit(1)
#### bunlar CIFAR için bunu MNIST içintekrardan hesapla ve hesaplarken fetarue space çıktısı da al
#şimdilik rastgele classlar için deniyor olacağım

target_classes_mapping = {
    0: 6,  # 0 -> 6
    1: 7,  # 1 -> 7
    2: 3,  # 2 -> 3
    3: 8,  # 3 -> 8
    4: 9,  # 4 -> 9
    5: 3,  # 5 -> 3
    6: 8,  # 6 -> 8 (or 0, 5)
    7: 1,  # 7 -> 1
    8: 6,  # 8 -> 3 (or 0, 6)
    9: 8   # 9 -> 4 (or 7)
}

# target_classes_mapping = { ## best centroid calculation so far that aligns with feature map extraction
#     0: 6,  # 0 -> 6
#     1: 7,  # 1 -> 7
#     2: 3,  # 2 -> 3
#     3: 8,  # 3 -> 8
#     4: 9,  # 4 -> 9
#     5: 3,  # 5 -> 3
#     6: 8,  # 6 -> 8 (or 0, 5)
#     7: 1,  # 7 -> 1
#     8: 3,  # 8 -> 3 (or 0, 6)
#     9: 4   # 9 -> 4 (or 7)
# }

epsilon = 0.01

def save_image_with_classification(image_data, classification, filepath):
    image = np.transpose(image_data.squeeze(0).detach().numpy(), (1, 2, 0))
    image = np.clip(image, 0, 1)
    plt.imshow(image)
    plt.title(classification)
    plt.axis('off')
    plt.savefig(filepath)
    plt.close()

def targeted_jsma_attack(model, data, target_class, epsilon=epsilon, num_classes=10):
    data.requires_grad = True
    output = model(data)

    gradients = []
    for i in range(num_classes):
        model.zero_grad()
        output[0, i].backward(retain_graph=True)
        gradients.append(data.grad.data.clone())
        data.grad.data.zero_()
    gradients = torch.stack(gradients)  # Shape: [num_classes, 3, 32, 32] this might not be true since mnist dataset includes images with 1 channel and not 3 as RGB yet only black and white

    target_grad = gradients[target_class]
    saliency_map = target_grad.sign()

    perturbation = epsilon * saliency_map
    perturbed_data = data + perturbation
    perturbed_data = torch.clamp(perturbed_data, 0, 1)

    return perturbed_data

class_names = datasets.MNIST(root='./data', train=True, download=True).classes

# Data transformation and loading
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.1307,), (0.3081,))
])
test_data = datasets.MNIST(root='./data', train=False, download=True, transform=transform)
test_loader = DataLoader(test_data, batch_size=1, shuffle=True)

num_images = 300
output_dir = './output_images'
os.makedirs(output_dir, exist_ok=True)

all_labels = []
all_original_preds = []
all_adversarial_preds = []
target_class_success = 0  # Tracks how many perturbed images are classified as the target class
correct_original = 0
correct_adversarial = 0
num_perturbed_images = 0


for i in range (3):
    for i, (data, target) in enumerate(test_loader):
        if i >= num_images:
            break

        data, target = data.to('cpu'), target.to('cpu')
        all_labels.append(target.item())

        # Original prediction
        with torch.no_grad():
            output = net(data)
        original_pred = output.argmax(dim=1).item()
        all_original_preds.append(original_pred)
        correct_original += (original_pred == target.item())

        original_filepath = os.path.join(output_dir, f'original_{i}_label_{target.item()}.png')
        save_image_with_classification(data, class_names[target.item()], original_filepath)


        # Generate adversarial example
        target_class = target_classes_mapping.get(target.item(), target.item())
        adversarial_data = targeted_jsma_attack(net, data.clone(), target_class=target_class, epsilon=epsilon)

        #increment the number of perturbed images
        num_perturbed_images += 1

        # Adversarial prediction
        with torch.no_grad():
            output = net(adversarial_data)
        adversarial_pred = output.argmax(dim=1).item()
        correct_adversarial += (adversarial_pred == target_class)

        # Save adversarial image
        adversarial_filepath = os.path.join(output_dir, f'adversarial_{i}_label_{target.item()}_target_{target_class}.png')
        save_image_with_classification(adversarial_data, class_names[adversarial_pred], adversarial_filepath)  # Assuming adversarial_pred is the predicted class for the adversarial

    accuracy_original_before_masking = (correct_original / num_images) * 100
    accuracy_adversarial_before_masking = (correct_adversarial / num_perturbed_images) * 100

    print(f"\nAccuracy on original images: {accuracy_original_before_masking:.2f}%")
    print(f"Accuracy on adversarial images: {accuracy_adversarial_before_masking:.2f}%")

    all_labels = []
    all_original_preds = []
    all_adversarial_preds = []
    target_class_success = 0  # Tracks how many perturbed images are classified as the target class
    correct_original = 0
    correct_adversarial = 0
    num_perturbed_images = 0
