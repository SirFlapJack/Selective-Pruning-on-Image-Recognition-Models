import os
import numpy as np
import matplotlib.pyplot as plt
import torchvision.models as models
import torch
import torch.nn as nn
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

net = models.resnet18(weights=None, num_classes=10)
try:
    net.load_state_dict(torch.load('/content/image_recognition_model.pth', map_location=torch.device('cpu')))
    net.eval()
except FileNotFoundError:
    print("Error: Model file not found. Ensure '/content/image_recognition_model.pth' exists.")
    exit(1)

target_classes_mapping = {
    0: 2,  # airplane -> bird
    1: 0,  # automobile -> airplane
    2: 3,  # bird -> cat
    3: 5,  # cat -> dog
    4: 3,  # deer -> cat
    5: 3,  # dog -> cat
    6: 3,  # frog -> cat
    7: 3,  # horse -> cat
    8: 1,  # ship -> automobile
    9: 0   # truck -> airplane
}

epsilon = 0.01

def targeted_jsma_attack(model, data, target_class, epsilon=epsilon, num_classes=10):
    data.requires_grad = True
    output = model(data)

    gradients = []
    for i in range(num_classes):
        model.zero_grad()
        output[0, i].backward(retain_graph=True)
        gradients.append(data.grad.data.clone())
        data.grad.data.zero_()
    gradients = torch.stack(gradients)  # Shape: [num_classes, 3, 32, 32]

    target_grad = gradients[target_class]
    saliency_map = target_grad.sign()

    perturbation = epsilon * saliency_map
    perturbed_data = data + perturbation
    perturbed_data = torch.clamp(perturbed_data, 0, 1)

    return perturbed_data

def save_image_with_classification(image_data, classification, filepath):
    image = np.transpose(image_data.squeeze(0).detach().numpy(), (1, 2, 0))
    image = np.clip(image, 0, 1)
    plt.imshow(image)
    plt.title(classification)
    plt.axis('off')
    plt.savefig(filepath)
    plt.close()


class_names = datasets.CIFAR10(root='./data', train=True, download=True).classes

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])
test_data = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
test_loader = DataLoader(test_data, batch_size=1, shuffle=True)

num_images = 300
output_dir = './output_images'
os.makedirs(output_dir, exist_ok=True)

all_labels = []
all_original_preds = []
all_adversarial_preds = []
target_class_success = 0  # Tracks how many perturbed images are classified as the target class
correct_original = 0
correct_adversarial = 0
num_perturbed_images = 0

for i, (data, target) in enumerate(test_loader):
    if i >= num_images:
        break

    data, target = data.to('cpu'), target.to('cpu')
    all_labels.append(target.item())

    with torch.no_grad():
        output = net(data)
    original_pred = output.argmax(dim=1).item()
    all_original_preds.append(original_pred)
    correct_original += (original_pred == target.item())

    target_class = target_classes_mapping.get(target.item(), target.item())
    adversarial_data = targeted_jsma_attack(net, data.clone(), target_class=target_class, epsilon=epsilon)

    num_perturbed_images += 1

    with torch.no_grad():
        output = net(adversarial_data)
    adversarial_pred = output.argmax(dim=1).item()
    correct_adversarial += (adversarial_pred == target_class)


accuracy_original_before_masking = (correct_original / num_images) * 100
accuracy_adversarial_before_masking = (correct_adversarial / num_perturbed_images) * 100

print(f"\nAccuracy on original images: {accuracy_original_before_masking:.2f}%")
print(f"Accuracy on adversarial images: {accuracy_adversarial_before_masking:.2f}%")
